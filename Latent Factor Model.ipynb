{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Reading data and convert into sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "def read_file(file_path):\n",
    "    M = []\n",
    "\n",
    "    # Step 1: Load the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    # Step 2: Create mappings for user_id and item_id\n",
    "    user_ids = list(set(record['user_id'] for record in data))\n",
    "    item_ids = list(set(record['item_id'] for record in data))\n",
    "\n",
    "    user_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    item_map = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "\n",
    "    # Step 3: Initialize data storage for the design matrix\n",
    "    rows = []\n",
    "    cols = []\n",
    "    ratings = []\n",
    "\n",
    "    for record in data:\n",
    "        user_idx = user_map[record['user_id']]\n",
    "        item_idx = item_map[record['item_id']]\n",
    "        rating = record['rating']\n",
    "    \n",
    "        rows.append(user_idx)\n",
    "        cols.append(item_idx)\n",
    "        ratings.append(rating)\n",
    "\n",
    "    # Step 4: Create the sparse matrix\n",
    "    M = coo_matrix((ratings, (rows, cols)), shape=(len(user_ids), len(item_ids)))\n",
    "    pair = list(zip(M.row, M.col))\n",
    "\n",
    "    return M, user_map, item_map, pair\n",
    "\n",
    "train_path = '/Users/mac/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Campus/Smt II/COMPSCI 753/A2/Assignment2_Files/goodreads_reviews_young_adult_train.json'\n",
    "train, train_user, train_item, train_pair = read_file(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute Bias\n",
    "\n",
    "Report:\n",
    "- The global bias\n",
    "- The user specific bias of user id= “91ceb82d91493506532feb02ce751ce7”\n",
    "- The item specific bias of item id = “6931234”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias on training data = 3.7635\n",
      "User '91ceb82d91493506532feb02ce751ce7' bias = -0.4723\n",
      "Item '6931234' bias = -0.1301\n"
     ]
    }
   ],
   "source": [
    "# Estimate Global Bias On Training Data\n",
    "train_bias_g = train.data.mean()\n",
    "print(f\"Global bias on training data = {train_bias_g:.4f}\")\n",
    "\n",
    "# Estimate User Biar on Training Data\n",
    "## Dictionary to store user bias\n",
    "train_bias_u = {}\n",
    "\n",
    "def bias(id, M, map, g_bias, kind):\n",
    "    # get id on matrix\n",
    "    id_matrix = map.get(id)\n",
    "\n",
    "    # get user or item ratings\n",
    "    if kind == 'user':\n",
    "        rating = M.getrow(id_matrix).data\n",
    "    elif kind == 'item':\n",
    "        rating = M.getcol(id_matrix).data\n",
    "\n",
    "    # get only non-zero rating\n",
    "    if len(rating) > 0:\n",
    "        bias = np.mean(rating) - g_bias\n",
    "    else:\n",
    "        bias = 0\n",
    "\n",
    "    return bias\n",
    "\n",
    "# Retrieve User bias\n",
    "user_id = '91ceb82d91493506532feb02ce751ce7'\n",
    "user_bias = bias(user_id, train, train_user, train_bias_g, 'user')\n",
    "print(f\"User '{user_id}' bias = {user_bias:.4f}\")\n",
    "\n",
    "# Retrive Item Bias\n",
    "item_id = '6931234'\n",
    "item_bias = bias(item_id, train, train_item, train_bias_g, 'item')\n",
    "print(f\"Item '{item_id}' bias = {item_bias:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the regularized latent factor model without bias using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Implement the regularized latent factor model without considering the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "RMSE = 2.9178\n",
      "Iteration 2\n",
      "RMSE = 2.0650\n",
      "Iteration 3\n",
      "RMSE = 1.6939\n",
      "Iteration 4\n",
      "RMSE = 1.4836\n",
      "Iteration 5\n",
      "RMSE = 1.3500\n",
      "Iteration 6\n",
      "RMSE = 1.2593\n",
      "Iteration 7\n",
      "RMSE = 1.1950\n",
      "Iteration 8\n",
      "RMSE = 1.1477\n",
      "Iteration 9\n",
      "RMSE = 1.1121\n",
      "Iteration 10\n",
      "RMSE = 1.0846\n"
     ]
    }
   ],
   "source": [
    "# function to running SGD without considering bias\n",
    "def SGD_wo_bias(M, Q, Pt, eta, lambda1, lambda2, pair):\n",
    "    M = M.tocsr()\n",
    "    #Q = Q.astype(np.float64)\n",
    "    #Pt = Pt.astype(np.float64)\n",
    "    for i, j in pair:\n",
    "        eij = np.float16(0)\n",
    "        # compute error\n",
    "        eij = M[i, j] - np.dot(Q[i, :],Pt[:, j])\n",
    "        # update P and Q based on current error\n",
    "        Q[i, :] += eta * 2 * ( eij * Pt[:, j] - lambda1 * Q[i, :] )\n",
    "        Pt[:, j] += eta * 2 * ( eij * Q[i, :] -  lambda2 * Pt[:, j] )\n",
    "    return Q, Pt\n",
    "\n",
    "def rmse(M, Q, Pt, pair):\n",
    "    M = M.tocsr()\n",
    "    SSE = np.float64(0)\n",
    "    for i, j in pair:\n",
    "        eij = np.float16(0)\n",
    "         # make predictions from updated Q and P\n",
    "        pred = np.dot(Q[i, :], Pt[:, j])\n",
    "        # update error and Compute SSE based currrent Q and P\n",
    "        eij = M[i, j] - pred\n",
    "        SSE += eij ** 2\n",
    "    RMSE = np.sqrt(SSE/M.nnz)\n",
    "    return RMSE\n",
    "\n",
    "# Randomly initialize parameters k; epoches; P and Q matrices with normal distribution\n",
    "k = 8\n",
    "epoches = 10\n",
    "n_user, n_item = train.shape\n",
    "Q = np.random.normal(loc=0.0, scale=1.0, size=(n_user, k)).astype(np.float16)\n",
    "Pt = np.random.normal(loc=0.0, scale=1.0, size=(k, n_item)).astype(np.float16)\n",
    "# run 10 epoches SGD\n",
    "for iter in range(epoches):\n",
    "    Q, Pt = SGD_wo_bias(train, Q, Pt, 0.01, 0.3, 0.3, train_pair)\n",
    "    RMSE = rmse(train, Q, Pt, train_pair)\n",
    "    print(f'Iteration {iter+1}\\nRMSE = {RMSE:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the output, with 10 epoches, our prediction get better as the decrease in RMSE. In the first iteration we get RMSE 2.9 and it turn to 0.8 after running 10 iteration SGD as we get more accurate gradient. The better gradient provided more accurate P and Q representation. It is confirm from the decreasae of total loss from first iteration to what we resullted in the last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Convert Validation and Test Data into Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import validation set\n",
    "val_path = '/Users/mac/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Campus/Smt II/COMPSCI 753/A2/Assignment2_Files/goodreads_reviews_young_adult_val.json'\n",
    "val, val_user, val_item, val_pair = read_file(val_path)\n",
    "\n",
    "# Import Test Set\n",
    "test_path = '/Users/mac/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Campus/Smt II/COMPSCI 753/A2/Assignment2_Files/goodreads_reviews_young_adult_test.json'\n",
    "test, test_user, test_item, test_pair = read_file(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding best k in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k = 4, RMSE = 3.2286\n",
      "for k = 8, RMSE = 3.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/1mshm_9545g9lr9vb6nd8vb80000gn/T/ipykernel_3223/2717766983.py:11: RuntimeWarning: overflow encountered in multiply\n",
      "  Q[i, :] += eta * 2 * ( eij * Pt[:, j] - lambda1 * Q[i, :] )\n",
      "/var/folders/j_/1mshm_9545g9lr9vb6nd8vb80000gn/T/ipykernel_3223/2717766983.py:12: RuntimeWarning: overflow encountered in multiply\n",
      "  Pt[:, j] += eta * 2 * ( eij * Q[i, :] -  lambda2 * Pt[:, j] )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m Pt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39m(k, n_item))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoches):\n\u001b[0;32m----> 9\u001b[0m     Q, Pt \u001b[38;5;241m=\u001b[39m \u001b[43mSGD_wo_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pair\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Using updated Q and Pt we get from training for each k on validation set \u001b[39;00m\n\u001b[1;32m     11\u001b[0m RMSE \u001b[38;5;241m=\u001b[39m rmse(val, Q, Pt, val_pair)\n",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mSGD_wo_bias\u001b[0;34m(M, Q, Pt, eta, lambda1, lambda2, pair)\u001b[0m\n\u001b[1;32m      7\u001b[0m eij \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat16(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# compute error\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m eij \u001b[38;5;241m=\u001b[39m \u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(Q[i, :],Pt[:, j])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# update P and Q based on current error\u001b[39;00m\n\u001b[1;32m     11\u001b[0m Q[i, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m eta \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ( eij \u001b[38;5;241m*\u001b[39m Pt[:, j] \u001b[38;5;241m-\u001b[39m lambda1 \u001b[38;5;241m*\u001b[39m Q[i, :] )\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_csr.py:24\u001b[0m, in \u001b[0;36m_csr_base.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     27\u001b[0m         key \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_index.py:57\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[0;32m---> 57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_intXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_compressed.py:716\u001b[0m, in \u001b[0;36m_cs_matrix._get_intXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    714\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    715\u001b[0m major, minor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((row, col))\n\u001b[0;32m--> 716\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39msum(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train different k on training data\n",
    "cand_k = [4, 8, 16]\n",
    "for k in cand_k:\n",
    "    epoches = 10\n",
    "    n_user, n_item = train.shape\n",
    "    Q = np.random.normal(loc=0.0, scale=1.0, size=(n_user, k)).astype(np.float32)\n",
    "    Pt = np.random.normal(loc=0.0, scale=1.0, size=(k, n_item)).astype(np.float32)\n",
    "    for iter in range(epoches):\n",
    "        Q, Pt = SGD_wo_bias(train, Q, Pt, 0.01, 0.3, 0.3, train_pair)\n",
    "    # Using updated Q and Pt we get from training for each k on validation set \n",
    "    RMSE = rmse(val, Q, Pt, val_pair)\n",
    "    print(f'for k = {k}, RMSE = {RMSE:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameter k = 16 to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for k=16 on test data = 2.7333\n"
     ]
    }
   ],
   "source": [
    "# using updated Q and Pt, make pred in test data and get RMSE\n",
    "RMSE = rmse(test, Q, Pt, test_pair)\n",
    "print(f'RMSE for k=4 on test data = {RMSE:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement Regularization with considering bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = train.shape\n",
    "Bu = np.zeros(n_user)\n",
    "ij = 0\n",
    "i = train.row[ij]\n",
    "j = train.col[ij]\n",
    "user_rate = train.getrow(i).toarray().flatten()\n",
    "item_rate = train.getcol(j).toarray()\n",
    "Bu[i] = np.mean(user_rate) - 2.7\n",
    "print(user_rate[6428])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/1mshm_9545g9lr9vb6nd8vb80000gn/T/ipykernel_4028/3450270326.py:17: RuntimeWarning: overflow encountered in multiply\n",
      "  Q[i, :] = Q[i, :] + 2*eta*eij*Pt[:, j] - 2*eta*lambda1*Q[i, :]\n",
      "/var/folders/j_/1mshm_9545g9lr9vb6nd8vb80000gn/T/ipykernel_4028/3450270326.py:18: RuntimeWarning: overflow encountered in multiply\n",
      "  Pt[:, j] = Pt[:, j] + 2*eta*eij*Q[i, :] - 2*eta*lambda2*Pt[:, j]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m Q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39m(n_user, k))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     32\u001b[0m Pt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39m(k, n_item))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 33\u001b[0m Q, Pt, Bu, Bi, RMSE \u001b[38;5;241m=\u001b[39m \u001b[43mSGD_w_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_bias_g\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration, RMSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRMSE\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mSGD_w_bias\u001b[0;34m(M, Q, Pt, eta, lambda1, lambda2, lambda3, lambda4, pair, g_bias)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m pair:\n\u001b[1;32m     10\u001b[0m     user_rate \u001b[38;5;241m=\u001b[39m M_csr[i, :]\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 11\u001b[0m     item_rate \u001b[38;5;241m=\u001b[39m \u001b[43mM_csr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     12\u001b[0m     Bu[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(user_rate) \u001b[38;5;241m-\u001b[39m g_bias\n\u001b[1;32m     13\u001b[0m     Bi[j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(item_rate) \u001b[38;5;241m-\u001b[39m g_bias\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_csr.py:24\u001b[0m, in \u001b[0;36m_csr_base.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     27\u001b[0m         key \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_index.py:70\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_sliceXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m row \u001b[38;5;241m==\u001b[39m col:\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_csr.py:264\u001b[0m, in \u001b[0;36m_csr_base._get_sliceXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_sliceXint\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col):\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_submatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_slice(row)\u001b[38;5;241m.\u001b[39m_get_submatrix(minor\u001b[38;5;241m=\u001b[39mcol)\n",
      "File \u001b[0;32m~/anaconda3/envs/Masiv_data/lib/python3.12/site-packages/scipy/sparse/_compressed.py:887\u001b[0m, in \u001b[0;36m_cs_matrix._get_submatrix\u001b[0;34m(self, major, minor, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i1 \u001b[38;5;241m==\u001b[39m M \u001b[38;5;129;01mand\u001b[39;00m j1 \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 887\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((i1 \u001b[38;5;241m-\u001b[39m i0, j1 \u001b[38;5;241m-\u001b[39m j0))\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# function to run SGD with considering bias\n",
    "def SGD_w_bias(M, Q, Pt, eta, lambda1, lambda2, lambda3, lambda4, pair, g_bias):\n",
    "    SSE = np.longdouble(0)\n",
    "    M_csr = M.tocsr()\n",
    "    n_user, n_item = M.shape\n",
    "    Bu = np.zeros(n_user)\n",
    "    Bi = np.zeros(n_item)\n",
    "\n",
    "    for i, j in pair:\n",
    "        user_rate = M_csr[i, :].toarray().flatten()\n",
    "        item_rate = M_csr[:, j].toarray().flatten()\n",
    "        Bu[i] = np.mean(user_rate) - g_bias\n",
    "        Bi[j] = np.mean(item_rate) - g_bias\n",
    "        # Compute error\n",
    "        eij = M_csr[i, j] - (np.dot(Q[i, :], Pt[:, j]) + g_bias + Bu[i] + Bi[j])\n",
    "        # update P and Q based on current error\n",
    "        Q[i, :] = Q[i, :] + 2*eta*eij*Pt[:, j] - 2*eta*lambda1*Q[i, :]\n",
    "        Pt[:, j] = Pt[:, j] + 2*eta*eij*Q[i, :] - 2*eta*lambda2*Pt[:, j]\n",
    "        Bu[i] += eta * 2 * (eij - lambda3 * Bu[i])\n",
    "        Bi[j] += eta * 2 * (eij - lambda4 * Bi[j])\n",
    "        # Make prediction based on current updated Q and Pt\n",
    "        pred = ((np.dot(Q[i, :], Pt[:, j])) + g_bias + Bu[i] + Bi[j])\n",
    "        # Update the error based on current prediction\n",
    "        eij = M_csr[i, j] - pred\n",
    "        SSE += eij ** 2\n",
    "\n",
    "    RMSE = np.sqrt(SSE / M.nnz)\n",
    "    return Q, Pt, Bu, Bi, RMSE\n",
    "\n",
    "k = 8\n",
    "Q = np.random.normal(loc=0.0, scale=1.0, size=(n_user, k)).astype(np.float32)\n",
    "Pt = np.random.normal(loc=0.0, scale=1.0, size=(k, n_item)).astype(np.float32)\n",
    "Q, Pt, Bu, Bi, RMSE = SGD_w_bias(train, Q, Pt, 0.01, 0.3, 0.3, 0.3, 0.3, train_pair, train_bias_g)\n",
    "print(f'Iteration, RMSE = {RMSE:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.2789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "# Number of users and items\n",
    "num_users = 1000000\n",
    "num_items = 889000\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "num_ratings = 500  # Number of ratings\n",
    "\n",
    "data = np.random.randint(1, 6, size=num_ratings)  # Ratings between 1 and 5\n",
    "row = np.random.randint(0, num_users, size=num_ratings)  # User indices\n",
    "col = np.random.randint(0, num_items, size=num_ratings)  # Item indices\n",
    "\n",
    "# Create the coo_matrix\n",
    "R = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def SGD_w_bias(M, k, eta, lambda1, lambda2, lambda3, lambda4, g_bias):\n",
    "    MSE = 0\n",
    "    ratings = M.data\n",
    "    n_user, n_item = M.shape\n",
    "    Bu = np.zeros(n_user)\n",
    "    Bi = np.zeros(n_item)\n",
    "    Q = np.random.normal(size=(n_user, k))\n",
    "    Pt = np.random.normal(size=(k, n_item))\n",
    "    \n",
    "    for ij in range(len(ratings)):\n",
    "        rij = ratings[ij]\n",
    "        i = M.indices[ij]\n",
    "        j = M.indptr[ij]\n",
    "        if rij > 0:\n",
    "            row_data = M[i,:].data\n",
    "            col_data = M[:, j].data\n",
    "            if len(row_data) > 0:\n",
    "                Bu[i] = np.mean(row_data) - g_bias\n",
    "            if len(col_data) > 0:\n",
    "                Bi[j] = np.mean(col_data) - g_bias\n",
    "            eij = rij - ((np.dot(Q[i, :], Pt[:, j])) + g_bias + Bu[i] + Bi[j])\n",
    "            # Update Q, Pt, Bu, Bi\n",
    "            Q[i, :] = Q[i, :] + eta * 2 * (eij * Pt[:, j] - lambda1 * Q[i, :])\n",
    "            Pt[:, j] = Pt[:, j] + eta * 2 * (eij * Q[i, :] - lambda2 * Pt[:, j])\n",
    "            Bu[i] = Bu[i] + eta * 2 * (eij - lambda3 * Bu[i])\n",
    "            Bi[j] = Bi[j] + eta * 2 * (eij - lambda4 * Bi[j])\n",
    "            # Make prediction based on current updated Q and Pt\n",
    "            pred = ((np.dot(Q[i, :], Pt[:, j])) + g_bias + Bu[i] + Bi[j])\n",
    "            # Update the error based on current prediction\n",
    "            eij = rij - pred\n",
    "            MSE += eij ** 2\n",
    "    RMSE = np.sqrt(MSE / len(ratings))\n",
    "    return Q, Pt, Bu, Bi, RMSE\n",
    "\n",
    "\n",
    "# Example global bias\n",
    "train_bias_g = np.mean(R.data)\n",
    "Q, Pt, Bu, Bi, RMSE = SGD_w_bias(R, k=8, eta=0.01, lambda1=0.3, lambda2=0.3, lambda3=0.3, lambda4=0.3, g_bias=train_bias_g)\n",
    "print(f'RMSE = {RMSE:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def read_file(file_path):\n",
    "    # Step 1: Load the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    # Step 2: Create mappings for user_id and item_id\n",
    "    user_ids = list(set(record['user_id'] for record in data))\n",
    "    item_ids = list(set(record['item_id'] for record in data))\n",
    "\n",
    "    user_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    item_map = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "\n",
    "    # Step 3: Initialize the NumPy matrix\n",
    "    M = np.zeros((len(user_ids), len(item_ids)))\n",
    "\n",
    "    for record in data:\n",
    "        user_idx = user_map[record['user_id']]\n",
    "        item_idx = item_map[record['item_id']]\n",
    "        rating = record['rating']\n",
    "    \n",
    "        M[user_idx, item_idx] = rating\n",
    "\n",
    "    return M, user_map, item_map\n",
    "\n",
    "train_path = '/Users/mac/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Campus/Smt II/COMPSCI 753/A2/Assignment2_Files/goodreads_reviews_young_adult_train.json'\n",
    "train, train_user, train_item = read_file(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
